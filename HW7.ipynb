{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "from utils_ import feat_imp,reduce_mem_usage,make_feat,freq_enc,fill_cat_p\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "plt.style.use('tableau-colorblind10')\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold,cross_validate\n",
    "from scipy.stats import rankdata\n",
    "%matplotlib inline\n",
    "%config inlinebackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bki():\n",
    "    \n",
    "    bki = pd.read_csv('bki.csv')\n",
    "    \n",
    "    CREDIT_TYPE_list=['Consumer credit', 'Credit card', 'Car loan', 'Mortgage',\n",
    "           'Loan for business development', 'Microloan']    \n",
    "    cat_feat=['APPLICATION_NUMBER']\n",
    "    cat_feat.extend(bki.select_dtypes(include='object').columns.tolist())\n",
    "    bki_gr=bki.groupby(cat_feat, as_index=False).mean()\n",
    "    \n",
    "    return bki_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_client_profile():\n",
    "    \n",
    "    client_profile = pd.read_csv('client_profile.csv ')\n",
    "    \n",
    "    client_profile.FAMILY_STATUS.replace('Unknown','Married', inplace=True)\n",
    "    client_profile.GENDER.fillna('F',inplace=True)\n",
    "    client_profile['AMT_REQ_CREDIT_BUREAU']=(client_profile.AMT_REQ_CREDIT_BUREAU_HOUR+\n",
    "                                             24*client_profile.AMT_REQ_CREDIT_BUREAU_HOUR+\n",
    "                                             30*24*client_profile.AMT_REQ_CREDIT_BUREAU_DAY+\n",
    "                                             30*24*30*client_profile.AMT_REQ_CREDIT_BUREAU_MON+\n",
    "                                             30*24*30*3*client_profile.AMT_REQ_CREDIT_BUREAU_DAY+\n",
    "                                             30*24*30*3*4*client_profile.AMT_REQ_CREDIT_BUREAU_DAY)\n",
    "\n",
    "    \n",
    "    return client_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_payments():\n",
    "    \n",
    "    payments= pd.read_csv('payments.csv')\n",
    "    \n",
    "    payments.DAYS_ENTRY_PAYMENT.fillna(payments.DAYS_INSTALMENT, inplace=True)\n",
    "    payments.AMT_PAYMENT.fillna(payments.AMT_INSTALMENT, inplace=True)\n",
    "    payments=pd.get_dummies(payments)\n",
    "    cat_feat=['APPLICATION_NUMBER']\n",
    "    cat_feat.extend(payments.select_dtypes(include='object').columns.tolist())\n",
    "    payments_gr=payments.groupby(cat_feat, as_index=False).mean()\n",
    "\n",
    "    return payments_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_applications_history():\n",
    "    \n",
    "    applications_history= pd.read_csv('applications_history.csv ')\n",
    "   \n",
    "    cat_feat=['APPLICATION_NUMBER']\n",
    "    cat_feat.extend(applications_history.select_dtypes(include='object').columns.tolist())\n",
    "    \n",
    "    applications_history_gr=applications_history.groupby(cat_feat, as_index=False).mean()\n",
    "\n",
    "    return applications_history_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(x):\n",
    "    bki = prep_bki()\n",
    "    client_profile=prep_client_profile()\n",
    "    payments=prep_payments()\n",
    "    applications_history=prep_applications_history()\n",
    "       \n",
    "    data_list={\n",
    "        'bki_gr':bki,\n",
    "        'client_profile':client_profile,\n",
    "           'payments_gr':payments,\n",
    "           'applications_history_gr':applications_history\n",
    "          }\n",
    "    \n",
    "    total = x.copy()\n",
    "    \n",
    "    for data in data_list.values():\n",
    " \n",
    "        total=total.merge(data,on='APPLICATION_NUMBER',how='left')\n",
    "\n",
    "    prep_x=total\n",
    "    return prep_x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 161.98 MB\n",
      "Memory usage after optimization is: 99.38 MB\n",
      "Decreased by 38.7%\n"
     ]
    }
   ],
   "source": [
    "train_prep0 = prep_data(train)\n",
    "train_prep0=reduce_mem_usage(train_prep0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep=train_prep0.copy()\n",
    "\n",
    "\n",
    "train_prep.EDUCATION_LEVEL=fill_cat_p(train_prep.EDUCATION_LEVEL)\n",
    "train_prep.GENDER=fill_cat_p(train_prep.GENDER)\n",
    "train_prep.FAMILY_STATUS=fill_cat_p(train_prep.FAMILY_STATUS)\n",
    "train_prep.CODE_REJECT_REASON=fill_cat_p(train_prep.CODE_REJECT_REASON)\n",
    "train_prep.NAME_PAYMENT_TYPE=fill_cat_p(train_prep.NAME_PAYMENT_TYPE)\n",
    "train_prep.NAME_CONTRACT_STATUS=fill_cat_p(train_prep.NAME_CONTRACT_STATUS)\n",
    "\n",
    "\n",
    "# train_prep=train_prep.fillna(0.01)\n",
    "\n",
    "t=train_prep.groupby('APPLICATION_NUMBER', as_index=False).PREV_APPLICATION_NUMBER_x.count()\n",
    "train_prep=train_prep.merge(t, on='APPLICATION_NUMBER',how='left')    \n",
    "train_prep['TOTAL_AMOUNT_CREDIT_d'] = train_prep.TOTAL_SALARY/train_prep.AMOUNT_CREDIT_x\n",
    "train_prep['TOTAL_AMOUNT_CREDIT_m'] = train_prep.TOTAL_SALARY-train_prep.AMOUNT_CREDIT_x\n",
    "train_prep['TOTAL_FAMILY_SIZE'] = train_prep.TOTAL_SALARY/train_prep.FAMILY_SIZE\n",
    "train_prep['AMOUNT_CREDIT_FAMILY_SIZE'] = train_prep.AMOUNT_CREDIT_x/train_prep.FAMILY_SIZE \n",
    "# train_prep['TOTAL_AMOUNT_CREDIT_SIZE'] = (train_prep.TOTAL_SALARY-train_prep.AMOUNT_CREDIT_x)/train_prep.FAMILY_SIZE \n",
    "train_prep['TOTAL_AMOUNT_CREDIT_p'] = (train_prep.TOTAL_SALARY-train_prep.AMOUNT_CREDIT_x)/train_prep.TOTAL_SALARY\n",
    "\n",
    "# train_prep['DAYS_AMOUNT_CREDIT'] = train_prep.AMOUNT_CREDIT_x/train_prep.DAYS_CREDIT\n",
    "train_prep['DAY_OVERDUE_AMOUNT_CREDIT'] = train_prep.AMOUNT_CREDIT_x/train_prep.CREDIT_DAY_OVERDUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_prep=pd.get_dummies(train_prep)\n",
    "cat_feat=train_prep.drop('TARGET',axis=1).select_dtypes(include='object').columns.tolist()\n",
    "train_prep=freq_enc(train_prep, cat_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep=train_prep.groupby('APPLICATION_NUMBER', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_prep.TARGET\n",
    "x=train_prep.drop('TARGET',axis=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.8, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить алгоритмы LightGBM и XGBoost, получить OOF прогнозы, оценить корреляцию прогнозов на обучающей выборке. Применить модели на тестовую выборку и оценить корреляцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xg = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.09,\n",
    "    'reg_alpha':0.6,\n",
    "    'min_child_weight':30,\n",
    "#     'max_delta_step':50,\n",
    "    \"n_estimators\": 300,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 4,\n",
    "#     \"nthread\": 6,\n",
    "    \"seed\": 101\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"verbose\": 0,\n",
    "    'grow_policy':'SymmetricTree',\n",
    "#     'cat_features':cat_feat,\n",
    "    \"max_depth\": 6,\n",
    "    \"l2_leaf_reg\": 50,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 10,\n",
    "    'random_seed': 101,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lb = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.01,\n",
    "#     \"min_child_weight\": 0.001,\n",
    "    \"max_depth\": 9,\n",
    "    \"subsample_for_bin\":10000,\n",
    "    \"n_estimators\": 300,\n",
    "    \"n_jobs\": 6,\n",
    "    \"seed\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.725501\tvalid_1's auc: 0.71313\n",
      "[200]\ttraining's auc: 0.744741\tvalid_1's auc: 0.718715\n",
      "[300]\ttraining's auc: 0.759898\tvalid_1's auc: 0.72135\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\ttraining's auc: 0.759898\tvalid_1's auc: 0.72135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=9, metric='auc', n_estimators=300,\n",
       "               n_jobs=6, objective='binary', seed=27, subsample_for_bin=10000)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lightgbm.LGBMClassifier(**params_lb)\n",
    "lgb.fit(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.58714\tvalidation_1-auc:0.59208\n",
      "[50]\tvalidation_0-auc:0.72064\tvalidation_1-auc:0.71857\n",
      "[100]\tvalidation_0-auc:0.73522\tvalidation_1-auc:0.72271\n",
      "[150]\tvalidation_0-auc:0.74218\tvalidation_1-auc:0.72385\n",
      "[200]\tvalidation_0-auc:0.74218\tvalidation_1-auc:0.72385\n",
      "[235]\tvalidation_0-auc:0.74218\tvalidation_1-auc:0.72385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=4, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.09, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=30, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=300, n_jobs=8,\n",
       "              num_parallel_tree=1, random_state=101, reg_alpha=0.6,\n",
       "              reg_lambda=100, scale_pos_weight=1, seed=101, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(**params_xg)\n",
    "xgb.fit(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(x_train, y_train), \n",
    "              (x_test, y_test)],\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_xgb=xgb.predict_proba(x_train)[:,1]\n",
    "pred_train_lgb=lgb.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.9706696],\n",
       "       [0.9706696, 1.       ]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(pred_train_xgb,pred_train_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_xgb=xgb.predict_proba(x_test)[:,1]\n",
    "pred_test_lgb=lgb.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.97249409],\n",
       "       [0.97249409, 1.        ]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(pred_test_xgb,pred_test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Достаточно высокая корреляция на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего и усреднить ранги, сделать выводы о качестве отдельных моделей и о качестве комбинации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_mean=0.5*(pred_train_xgb+pred_train_lgb)\n",
    "pred_test_mean=0.5*(pred_test_xgb+pred_test_lgb)\n",
    "pred_train_sqrt=list(map(lambda x:(x[0]*x[1])**0.5,list(zip(pred_train_xgb,pred_train_lgb))))\n",
    "pred_test_sqrt=list(map(lambda x:(x[0]*x[1])**0.5,list(zip(pred_test_xgb,pred_test_lgb))))\n",
    "pred_train_rank=0.5*(rankdata(pred_train_xgb)+rankdata(pred_train_lgb))\n",
    "pred_test_rank=0.5*(rankdata(pred_test_xgb)+rankdata(pred_test_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb  train:  0.742 test:  0.7241 +\\- :  0.0179\n",
      "lgb  train:  0.7599 test:  0.7214 +\\- :  0.0385\n",
      "mean train:  0.7525 test:  0.7234 +\\- :  0.0291\n",
      "sqrt train:  0.7519 test:  0.7234 +\\- :  0.0285\n",
      "rank train:  0.7525 test:  0.7236 +\\- :  0.0289\n"
     ]
    }
   ],
   "source": [
    "metrcics={'xgb ':[pred_train_xgb,pred_test_xgb],\n",
    "         'lgb ':[pred_train_lgb,pred_test_lgb],\n",
    "         'mean': [pred_train_mean,pred_test_mean],\n",
    "         'sqrt': [pred_train_sqrt,pred_test_sqrt],\n",
    "         'rank': [pred_train_rank,pred_test_rank]}\n",
    "\n",
    "for metr,means in metrcics.items():\n",
    "    \n",
    "    print(metr,'train: ', round(roc_auc_score(y_train, means[0]),4),\\\n",
    "          'test: ',round(roc_auc_score(y_test, means[1]),4),\n",
    "         '+\\- : ',round(roc_auc_score(y_train, means[0])-roc_auc_score(y_test, means[1]),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наиболее интересные результаты у xgb и rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить CatBoost, получить OOF прогнозы и выполнить задание 1 для трех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6092005\ttest1: 0.6030648\tbest: 0.6030648 (0)\ttotal: 50.5ms\tremaining: 15.1s\n",
      "100:\ttest: 0.7151446\ttest1: 0.7177755\tbest: 0.7177755 (100)\ttotal: 4.35s\tremaining: 8.57s\n",
      "200:\ttest: 0.7280594\ttest1: 0.7228348\tbest: 0.7228348 (200)\ttotal: 8.65s\tremaining: 4.26s\n",
      "299:\ttest: 0.7375204\ttest1: 0.7241544\tbest: 0.7242113 (298)\ttotal: 12.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7242113342\n",
      "bestIteration = 298\n",
      "\n",
      "Shrink model to first 299 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1c4b47f89d0>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = catboost.CatBoostClassifier(**params_cb)\n",
    "cb.fit(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "    \n",
    "    verbose=100,\n",
    "    plot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_cb=cb.predict_proba(x_train)[:,1]\n",
    "pred_test_cb=cb.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb-cb : train  0.965 test  0.965 \n",
      "lgb-cb : train  0.9489 test  0.9489\n"
     ]
    }
   ],
   "source": [
    "print('xgb-cb : train ',round(np.corrcoef(pred_train_xgb,pred_train_cb)[0,1],4),\n",
    "      'test ', round(np.corrcoef(pred_train_xgb,pred_train_cb)[0,1],4),\n",
    "     '\\nlgb-cb : train ',round(np.corrcoef(pred_train_lgb,pred_train_cb)[0,1],4),\n",
    "      'test ', round(np.corrcoef(pred_train_lgb,pred_train_cb)[0,1],4),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Неплохая корреляция с xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнить задание 2 для трех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrcics['cb']=[pred_train_cb,pred_test_cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_mean=(pred_train_xgb+pred_train_lgb+pred_train_cb)/3\n",
    "pred_test_mean=(pred_test_xgb+pred_test_lgb+pred_test_cb)/3\n",
    "pred_train_sqrt=list(map(lambda x:(x[0]*x[1]*x[2])**(2/3),list(zip(pred_train_xgb,pred_train_lgb,pred_train_cb))))\n",
    "pred_test_sqrt=list(map(lambda x:(x[0]*x[1]*x[2])**(2/3),list(zip(pred_test_xgb,pred_test_lgb,pred_test_cb))))\n",
    "pred_train_rank=(rankdata(pred_train_xgb)+rankdata(pred_train_lgb)+rankdata(pred_train_cb))/3\n",
    "pred_test_rank=(rankdata(pred_test_xgb)+rankdata(pred_test_lgb)+rankdata(pred_test_cb))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb  train:  0.742 test:  0.7241 +\\- :  0.0179\n",
      "lgb  train:  0.7599 test:  0.7214 +\\- :  0.0385\n",
      "cb   train:  0.7375 test:  0.7242 +\\- :  0.0133\n",
      "mean train:  0.7493 test:  0.7248 +\\- :  0.0244\n",
      "sqrt train:  0.7488 test:  0.7249 +\\- :  0.0239\n",
      "rank train:  0.7489 test:  0.7249 +\\- :  0.024\n"
     ]
    }
   ],
   "source": [
    "metrcics={'xgb ':[pred_train_xgb,pred_test_xgb],\n",
    "         'lgb ':[pred_train_lgb,pred_test_lgb],\n",
    "         'cb  ':[pred_train_cb,pred_test_cb],\n",
    "         'mean': [pred_train_mean,pred_test_mean],\n",
    "         'sqrt': [pred_train_sqrt,pred_test_sqrt],\n",
    "         'rank': [pred_train_rank,pred_test_rank]}\n",
    "\n",
    "for metr,means in metrcics.items():\n",
    "    \n",
    "    print(metr,'train: ', round(roc_auc_score(y_train, means[0]),4),\\\n",
    "          'test: ',round(roc_auc_score(y_test, means[1]),4),\n",
    "         '+\\- : ',round(roc_auc_score(y_train, means[0])-roc_auc_score(y_test, means[1]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# У cb неплохие показатели, композиционные алгоритмы подрасли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(опция) Объединить OOF-прогнозы для трех моделей и обучить алгоритм Логистической регрессии (и любой другой, на ваше усмотрение). Сделать выводы о достигаемом качестве, сравнить достигаемое качество с качеством отдельных моделей и моделей, полученных в п.2 и п.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc =LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_union=np.vstack((pred_train_xgb,pred_train_lgb,pred_train_cb)).T\n",
    "pred_test_union=np.vstack((pred_test_xgb,pred_test_lgb,pred_test_cb)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7138907847441142"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.fit(pred_train_union, y_train)\n",
    "pred_train_rc = rc.predict_proba(pred_test_union)\n",
    "roc_auc_score(y_test,pred_train_rc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# такое "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=VotingClassifier(estimators=[('xgb',xgb),('lgb',lgb),('cb', cb)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.724766422956113"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.fit(x_train, y_train)\n",
    "roc_auc_score(y_test,vc.predict_proba(x_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Неплохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(опция) Обучить алгоритмRandomForest (желательно подтюнить параметры) и добавить к построенным ранее моделям. Выполнить задание 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, n_estimators=300, random_state=101)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf =RandomForestClassifier(n_estimators=300,  max_depth=7,random_state=101 )\n",
    "rf.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7373674511753207, 0.7147431231371764)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_rf = rf.predict_proba(x_test)\n",
    "pred_train_rf = rf.predict_proba(x_train)\n",
    "\n",
    "roc_auc_score(y_train,pred_train_rf[:,1]), roc_auc_score(y_test,pred_test_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=VotingClassifier(estimators=[('xgb',xgb),('lgb',lgb),('cb', cb),('rf',rf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7239962762160652"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.fit(x_train, y_train)\n",
    "roc_auc_score(y_test,vc.predict_proba(x_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пойдет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
